# -*- coding: utf-8 -*-
"""
Created on Thu Apr 17 17:58:03 2025

@author: Xintang Zheng

æ˜Ÿæ˜Ÿ: â˜… â˜† âœª âœ© ğŸŒŸ â­ âœ¨ ğŸŒ  ğŸ’« â­ï¸
å‹¾å‹¾å‰å‰: âœ“ âœ” âœ• âœ– âœ… â
æŠ¥è­¦å•¦: âš  â“˜ â„¹ â˜£
ç®­å¤´: â” âœ â™ â¤ â¥ â†© â†ª
emoji: ğŸ”” â³ â° ğŸ”’ ğŸ”“ ğŸ›‘ ğŸš« â— â“ âŒ â­• ğŸš€ ğŸ”¥ ğŸ’§ ğŸ’¡ ğŸµ ğŸ¶ ğŸ§­ ğŸ“… ğŸ¤” ğŸ§® ğŸ”¢ ğŸ“Š ğŸ“ˆ ğŸ“‰ ğŸ§  ğŸ“

"""
# %%
import pandas as pd
import numpy as np
from concurrent.futures import ProcessPoolExecutor, as_completed
from tqdm import tqdm


# %%
def OAD(df, reference_time='0930', columns=None):
    """
    Calculate differences between each time point and a reference time for specified columns.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame with datetime index
    reference_time : str, default '09:30:00'
        Reference time in format 'HH:MM:SS' to compare against
    columns : list or None, default None
        List of columns to calculate differences for. If None, uses all columns in df.
    
    Returns:
    --------
    pandas.DataFrame
        DataFrame containing only the difference columns
    """
    
    # Make a copy to avoid modifying the original
    df = df.copy()
    
    # Ensure index is datetime format
    if not isinstance(df.index, pd.DatetimeIndex):
        df.index = pd.to_datetime(df.index)
    
    # If no columns specified, use all columns in the DataFrame
    if columns is None:
        columns = df.columns.tolist()
    
    # Convert reference time string to time object
    ref_time = pd.to_datetime(f'{reference_time[:2]}:{reference_time[2:]}').time()
    
    # Create reference columns for each specified column
    for col in columns:
        # Create a new column that only keeps values at reference time
        ref_col_name = f"{col}_{reference_time.replace(':', '')}"
        df[ref_col_name] = np.where(df.index.time == ref_time, df[col], np.nan)
    
    # Group by date and forward fill the reference values
    df = df.groupby(df.index.date).apply(lambda x: x.fillna(method='ffill'))
    
    # Reset index (remove multi-level index)
    df = df.reset_index(level=0, drop=True)
    
    # Calculate differences
    diff_columns = []
    for col in columns:
        ref_col_name = f"{col}_{reference_time.replace(':', '')}"
        diff_col_name = f"{col}_diff"
        df[diff_col_name] = df[col] - df[ref_col_name]
        diff_columns.append(diff_col_name)
    
    # Return only the difference columns
    return df[diff_columns]

# Example usage:
# Assuming 'df' is your DataFrame with datetime index
# result = calculate_time_differences(df, reference_time='09:31:00', 
#                                    columns=['call_oi_sum', 'put_oi_sum', 'pc', 'oi_imb01'])


# %% ma
def intraSma(data, window: int):
    """
    è®¡ç®—æ—¥å†…ç®€å•æ»‘åŠ¨çª—å£å‡å€¼ï¼Œç¡®ä¿æ¯å¤©çš„è®¡ç®—ä»…ä½¿ç”¨å½“å¤©çš„æ•°æ®ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…æ»‘åŠ¨å‡å€¼ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df.groupby(df.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—æ»‘åŠ¨å¹³å‡
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—æ»‘åŠ¨å¹³å‡
        day_result = group.rolling(window=window, min_periods=1).mean()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result

def intraEwma(data, span: int):
    """
    è®¡ç®—æ—¥å†…æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡(EWMA)ï¼Œç¡®ä¿æ¯å¤©çš„è®¡ç®—ä»…ä½¿ç”¨å½“å¤©çš„æ•°æ®ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        span (int): æŒ‡æ•°åŠ æƒçš„å‘¨æœŸæ•°ï¼Œç±»ä¼¼äºåŠè¡°æœŸã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df.groupby(df.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—EWMA
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—EWMAï¼Œadjust=Trueç¡®ä¿æ›´å‡†ç¡®çš„æŒ‡æ•°æƒé‡
        day_result = group.ewm(span=span, min_periods=1, adjust=True).mean()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result
    
    
def intraResetSma(data, window: int | str, reset_times=None):
    """
    ç»ˆæä¼˜åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨pandasçš„rollingå’Œgroupbyçš„é«˜çº§ç‰¹æ€§ã€‚
    """
    # é»˜è®¤é‡ç½®èŠ‚ç‚¹
    if reset_times is None:
        reset_times = ['10:01', '10:31', '11:01', '13:01', '13:31', '14:01', '14:31']
    
    is_series = isinstance(data, pd.Series)
    df = data.to_frame() if is_series else data.copy()
    
    # å‘é‡åŒ–åˆ›å»ºsegmentæ ‡è¯†
    reset_times_set = set(pd.to_datetime(reset_times).time)
    
    # åˆ›å»ºMultiIndexç”¨äºåˆ†ç»„
    dates = df.index.date
    times = df.index.time
    
    # å‘é‡åŒ–æ ‡è®°é‡ç½®ç‚¹å’Œæ—¥æœŸå˜åŒ–
    is_reset = pd.Series(times).isin(reset_times_set)
    is_new_day = pd.Series(dates) != pd.Series(dates).shift(1)
    
    # åˆ›å»ºsegmentåˆ†ç»„
    segment_breaks = pd.Series((is_reset | is_new_day).cumsum().values, index=df.index)
    
    # ä½¿ç”¨groupby + rollingçš„ç»„åˆè¿›è¡Œè¶…é«˜é€Ÿè®¡ç®—
    def fast_segment_rolling(group):
        return group.rolling(window=window, min_periods=1).mean()
    
    # ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰åˆ—
    grouped = df.groupby(segment_breaks, group_keys=False)
    result = grouped.apply(fast_segment_rolling)
    
    return result.iloc[:, 0] if is_series else result


def _detect_breaks(index, freq):
    """
    æ£€æµ‹æ—¶é—´åºåˆ—ä¸­è¶…è¿‡ç»™å®šé¢‘ç‡é—´éš”çš„æ–­ç‚¹
    
    Parameters:
    -----------
    index : pd.DatetimeIndex
        æ—¶é—´åºåˆ—ç´¢å¼•
    freq : str
        é¢‘ç‡å­—ç¬¦ä¸²ï¼Œå¦‚ '1min', '30min', '1H' ç­‰
        
    Returns:
    --------
    np.array
        æ–­ç‚¹ä½ç½®çš„å¸ƒå°”æ•°ç»„ï¼ŒTrueè¡¨ç¤ºè¯¥ä½ç½®æ˜¯æ–°ç»„çš„å¼€å§‹
    """
    if len(index) <= 1:
        return np.array([True] * len(index))
    
    # å°†é¢‘ç‡å­—ç¬¦ä¸²è½¬æ¢ä¸ºtimedelta
    freq_delta = pd.Timedelta(freq)
    
    # è®¡ç®—ç›¸é‚»æ—¶é—´ç‚¹çš„æ—¶é—´å·®
    time_diffs = index[1:] - index[:-1]
    
    # æ‰¾å‡ºè¶…è¿‡é¢‘ç‡é—´éš”çš„ä½ç½®
    breaks = time_diffs > freq_delta
    
    # ç¬¬ä¸€ä¸ªä½ç½®å§‹ç»ˆæ˜¯æ–°ç»„çš„å¼€å§‹
    breaks = np.concatenate([[True], breaks])
    
    return breaks


def _create_groups_by_freq(index, freq):
    """
    æ ¹æ®é¢‘ç‡é—´éš”åˆ›å»ºåˆ†ç»„æ ‡è¯†
    
    Parameters:
    -----------
    index : pd.DatetimeIndex
        æ—¶é—´åºåˆ—ç´¢å¼•
    freq : str
        é¢‘ç‡å­—ç¬¦ä¸²
        
    Returns:
    --------
    np.array
        åˆ†ç»„æ ‡è¯†æ•°ç»„
    """
    breaks = _detect_breaks(index, freq)
    group_ids = np.cumsum(breaks)
    return group_ids


def intraTEwma(data, span: int, freq: str = '1min'):
    """
    è®¡ç®—æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡(EWMA)ï¼ŒæŒ‰æŒ‡å®šé¢‘ç‡é—´éš”åˆ·æ–°è®¡ç®—ã€‚
    å½“å‰åä¸¤ä¸ªæ—¶é—´æˆ³ç›¸éš”è¶…è¿‡ç»™å®šfreqæ—¶ï¼ŒEWMAä¼šé‡æ–°å¼€å§‹è®¡ç®—ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        span (int): æŒ‡æ•°åŠ æƒçš„å‘¨æœŸæ•°ï¼Œç±»ä¼¼äºåŠè¡°æœŸã€‚
        freq (str): åˆ·æ–°é¢‘ç‡ï¼Œé»˜è®¤'1D'ï¼ˆæŒ‰æ—¥åˆ·æ–°ï¼‰ã€‚
                   å¯ä»¥æ˜¯ '1min', '30min', '1H', '2H' ç­‰ä»»æ„pandasé¢‘ç‡å­—ç¬¦ä¸²ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # ç¡®ä¿ç´¢å¼•æ˜¯datetimeç±»å‹
    if not isinstance(df.index, pd.DatetimeIndex):
        df.index = pd.to_datetime(df.index)
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®é¢‘ç‡åˆ›å»ºåˆ†ç»„æ ‡è¯†
    group_ids = _create_groups_by_freq(df.index, freq)
    
    # ä¸ºæ¯ä¸ªç»„å•ç‹¬è®¡ç®—EWMA
    for group_id in np.unique(group_ids):
        # è·å–å½“å‰ç»„çš„ç´¢å¼•ä½ç½®
        group_mask = group_ids == group_id
        group_data = df[group_mask]
        
        # å¯¹å½“å‰ç»„çš„æ•°æ®è®¡ç®—EWMAï¼Œadjust=Trueç¡®ä¿æ›´å‡†ç¡®çš„æŒ‡æ•°æƒé‡
        group_result = group_data.ewm(span=span, min_periods=1, adjust=True).mean()
        
        # å°†å½“å‰ç»„çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group_data.index] = group_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result


# ç¤ºä¾‹ç”¨æ³•ï¼š
# # æŒ‰1åˆ†é’Ÿé—´éš”åˆ·æ–°EWMAè®¡ç®—
# result = intraEwma(data, span=20, freq='1min')
# 
# # æŒ‰30åˆ†é’Ÿé—´éš”åˆ·æ–°EWMAè®¡ç®—  
# result = intraEwma(data, span=20, freq='30min')
# 
# # æŒ‰1å°æ—¶é—´éš”åˆ·æ–°EWMAè®¡ç®—
# result = intraEwma(data, span=20, freq='1H')
# 
# # ä¿æŒåŸæœ‰è¡Œä¸ºï¼ˆæŒ‰æ—¥åˆ·æ–°ï¼‰
# result = intraEwma(data, span=20, freq='1D')

    
# %%
def intraSum(data, window: int):
    """
    è®¡ç®—æ—¥å†…æ»‘åŠ¨çª—å£ç´¯è®¡æ±‚å’Œï¼Œç¡®ä¿æ¯å¤©çš„è®¡ç®—ä»…ä½¿ç”¨å½“å¤©çš„æ•°æ®ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        window (int): æ»‘åŠ¨çª—å£çš„å¤§å°ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…æ»‘åŠ¨æ±‚å’Œç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df.groupby(df.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—æ»‘åŠ¨æ±‚å’Œ
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—æ»‘åŠ¨æ±‚å’Œ
        day_result = group.rolling(window=window, min_periods=1).sum()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result
    
    
# %%
def process_intraCumSum_block(df_block, block_idx):
    """
    å¤„ç† intraCumSum çš„å•ä¸ªæ•°æ®å—
    """
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df_block.index, columns=df_block.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df_block.groupby(df_block.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—ç´¯è®¡æ±‚å’Œ
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—ç´¯è®¡æ±‚å’Œ
        day_result = group.cumsum()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    return block_idx, result


def intraCumSum_parallel(data, n_jobs: int = 150, block_size: int = 5):
    """
    intraCumSum çš„å¹¶è¡ŒåŠ é€Ÿç‰ˆæœ¬
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        n_jobs (int): å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œé»˜è®¤å€¼ä¸º 150ã€‚
        block_size (int): æ¯ä¸ªæ•°æ®å—çš„åˆ—æ•°ï¼Œé»˜è®¤å€¼ä¸º 5ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…ç´¯è®¡æ±‚å’Œç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # å°†æ•°æ®æŒ‰åˆ—åˆ†å—
    col_blocks = [df.columns[i:i+block_size] for i in range(0, len(df.columns), block_size)]
    result = pd.DataFrame(index=df.index, columns=df.columns)
    total_blocks = len(col_blocks)

    print(f"[intraCumSum_parallel] Launching {total_blocks} blocks with {n_jobs} processes...")

    with ProcessPoolExecutor(max_workers=n_jobs) as executor:
        future_to_idx = {}
        for block_idx, cols in enumerate(col_blocks):
            df_block = df[cols]
            future = executor.submit(process_intraCumSum_block, df_block, block_idx)
            future_to_idx[future] = (block_idx, cols)

        with tqdm(total=total_blocks, desc="intraCumSum Progress") as pbar:
            for future in as_completed(future_to_idx):
                block_idx, cols = future_to_idx[future]
                _, block_result = future.result()
                for col in cols:
                    result[col] = block_result[col]
                pbar.update(1)

    print("[intraCumSum_parallel] All blocks completed.")
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result


def intraCumSum(data):
    """
    è®¡ç®—æ—¥å†…ç´¯è®¡æ±‚å’Œï¼Œç¡®ä¿æ¯å¤©çš„è®¡ç®—ä»…ä½¿ç”¨å½“å¤©çš„æ•°æ®ï¼Œæ¯å¤©é‡æ–°å¼€å§‹ç´¯ç§¯ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…ç´¯è®¡æ±‚å’Œç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df.groupby(df.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—ç´¯è®¡æ±‚å’Œ
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—ç´¯è®¡æ±‚å’Œ
        day_result = group.cumsum()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result
    
    
# %%
def intraRmin(data, window: int):
    """
    è®¡ç®—æ—¥å†…æ»šåŠ¨æœ€å°å€¼ï¼Œç¡®ä¿æ¯å¤©çš„è®¡ç®—ä»…ä½¿ç”¨å½“å¤©çš„æ•°æ®ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        window (int): æ»šåŠ¨çª—å£çš„å¤§å°ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…æ»šåŠ¨æœ€å°å€¼ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df.groupby(df.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—æ»šåŠ¨æœ€å°å€¼
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—æ»šåŠ¨æœ€å°å€¼ï¼Œmin_periods=1ç¡®ä¿ä»ç¬¬ä¸€ä¸ªå€¼å¼€å§‹è®¡ç®—
        day_result = group.rolling(window=window, min_periods=1).min()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result


def intraRmax(data, window: int):
    """
    è®¡ç®—æ—¥å†…æ»šåŠ¨æœ€å¤§å€¼ï¼Œç¡®ä¿æ¯å¤©çš„è®¡ç®—ä»…ä½¿ç”¨å½“å¤©çš„æ•°æ®ã€‚
    
    Args:
        data: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå¯ä»¥æ˜¯DataFrameæˆ–Seriesï¼Œindexä¸ºæ—¶é—´æˆ³ã€‚
        window (int): æ»šåŠ¨çª—å£çš„å¤§å°ã€‚
        
    Returns:
        ä¸è¾“å…¥ç›¸åŒç±»å‹çš„æ—¥å†…æ»šåŠ¨æœ€å¤§å€¼ç»“æœï¼Œç»“æ„ä¸è¾“å…¥ä¸€è‡´ã€‚
    """
    # åˆ¤æ–­è¾“å…¥æ˜¯DataFrameè¿˜æ˜¯Series
    is_series = isinstance(data, pd.Series)
    
    # å¦‚æœæ˜¯Seriesï¼Œè½¬æ¢ä¸ºDataFrameå¤„ç†ï¼Œæ–¹ä¾¿ç»Ÿä¸€é€»è¾‘
    if is_series:
        df = data.to_frame()
    else:
        df = data.copy()
    
    # åˆ›å»ºä¸€ä¸ªä¸è¾“å…¥ç›¸åŒç»“æ„çš„ç»“æœDataFrame
    result = pd.DataFrame(index=df.index, columns=df.columns)
    
    # æ ¹æ®æ—¥æœŸå¯¹æ•°æ®è¿›è¡Œåˆ†ç»„
    grouped = df.groupby(df.index.date)
    
    # å¯¹æ¯ä¸€å¤©çš„æ•°æ®å•ç‹¬è®¡ç®—æ»šåŠ¨æœ€å¤§å€¼
    for date, group in grouped:
        # å¯¹å½“å¤©çš„æ•°æ®è®¡ç®—æ»šåŠ¨æœ€å¤§å€¼ï¼Œmin_periods=1ç¡®ä¿ä»ç¬¬ä¸€ä¸ªå€¼å¼€å§‹è®¡ç®—
        day_result = group.rolling(window=window, min_periods=1).max()
        
        # å°†å½“å¤©çš„ç»“æœå¡«å…¥æ€»ç»“æœä¸­
        result.loc[group.index] = day_result
    
    # å¦‚æœè¾“å…¥æ˜¯Seriesï¼Œåˆ™è¿”å›Seriesï¼Œå¦åˆ™è¿”å›DataFrame
    if is_series:
        return result.iloc[:, 0]
    else:
        return result